{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c712435",
   "metadata": {},
   "source": [
    "\n",
    "# Inventory Value Prediction Notebook\n",
    " \n",
    "**Objective:** Build an end-to-end machine learning pipeline to predict inventory value based on historical manufacturing and sales data. This notebook is structured for non-technical stakeholders, explaining each step of the Data Science and Machine Learning methodology.\n",
    "\n",
    "## 1. Problem Definition\n",
    " \n",
    "- **Business Context:** A coffee manufacturing plant needs to forecast daily inventory value to optimize purchasing and storage costs.\n",
    "- **Goal:** Predict the inventory value at the end of each day using past production volumes, sales orders, and other operational metrics.\n",
    "- **Stakeholders:** Production Engineers, Supply Chain Managers, Finance Team.\n",
    "- **Key Questions:**\n",
    "- How much inventory value will we hold tomorrow?\n",
    "- What factors most influence inventory valuation?\n",
    "- Can we reduce holding costs and stockouts?\n",
    "\n",
    "## 2. Methodology Overview\n",
    " \n",
    "We will follow a structured Data Science methodology:\n",
    "1. Data Collection & Generation\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Data Preprocessing & Feature Engineering\n",
    "4. Model Selection & Training\n",
    "5. Model Evaluation\n",
    "6. Deployment Plan & Next Steps\n",
    "\n",
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198bd9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0c078f",
   "metadata": {},
   "source": [
    "## 4. Synthetic Data Generation\n",
    " \n",
    "Since real data is not yet available, we generate a realistic synthetic dataset representing daily records over two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(1997)\n",
    "\n",
    "# create a date range for two years\n",
    "dates = pd.date_range(start='2023-01-01', end='2024-12-31', freq='D')\n",
    "n = len(dates)\n",
    "\n",
    "# Simulate production volume (kg), sales orders (kg), unit cost (SAR), holding cost rate\n",
    "production = np.random.normal(loc=500, scale=50, size=n).clip(min=300)\n",
    "sales = (production * np.random.uniform(0.7, 1.0, size=n)).round()\n",
    "unit_cost = np.random.uniform(2.5, 3.5, size=n)\n",
    "holding_cost_rate = 0.01  # 1% of inventory value per day\n",
    "\n",
    "# Calculate inventory value based on cumulative production minus cumulative sales\n",
    "cumulative_prod = np.cumsum(production)\n",
    "cumulative_sales = np.cumsum(sales)\n",
    "ending_inventory = (cumulative_prod - cumulative_sales).clip(min=0)\n",
    "inventory_value = ending_inventory * unit_cost\n",
    "\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'production_kg': production,\n",
    "    'sales_kg': sales,\n",
    "    'unit_cost_usd': unit_cost,\n",
    "    'ending_inventory_kg': ending_inventory,\n",
    "    'inventory_value_usd': inventory_value\n",
    "})\n",
    "\n",
    "# Save the synthetic dataset\n",
    "df.to_excel(r'D:\\1-My_GitHub_Repos\\Production-Engineering\\data\\data1.xlsx', index=False)\n",
    "\n",
    "# Preview\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1718066c",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)\n",
    "- Understand distributions\n",
    "- Check correlations\n",
    "- Visualize trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e5a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "corr = df.corr()\n",
    "print(corr['inventory_value_usd'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc1176",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing & Feature Engineering\n",
    " \n",
    "- Extract date-based features\n",
    "- Scale numeric variables\n",
    "- Prepare pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b296341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date features\n",
    "\n",
    "df['day_of_week'] = df['date'].dt.dayofweek\n",
    "df['month'] = df['date'].dt.month\n",
    "\n",
    "# Define features and target\n",
    "features = ['production_kg', 'sales_kg', 'unit_cost_usd', 'ending_inventory_kg', 'day_of_week', 'month']\n",
    "target = 'inventory_value_usd'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_features = ['production_kg', 'sales_kg', 'unit_cost_usd', 'ending_inventory_kg']\n",
    "categorical_features = ['day_of_week', 'month']\n",
    "\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7841efb8",
   "metadata": {},
   "source": [
    "## 7. Model Selection & Pipeline\n",
    "- We choose a Random Forest Regressor for its balance of performance and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdb12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538a899",
   "metadata": {},
   "source": [
    "## 8. Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e0121",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [50, 100],\n",
    "    'regressor__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1a298",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c9de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R2 Score: {r2:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d42d38",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Identify top drivers of inventory value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00720e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = best_model.named_steps['regressor'].feature_importance_\n",
    "feature_names = numeric_features + list(best_model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_features))\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "# %%\n",
    "plt.figure()\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.bar(range(len(importance)), importance[indices])\n",
    "plt.xticks(range(len(importance)), [feature_names[i] for i in indices], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68c2b3b",
   "metadata": {},
   "source": [
    "## 10. Deployment Plan\n",
    "\n",
    "- **Model Serialization:** Save the trained model using `joblib`.\n",
    "- **API Endpoint:** Wrap the model in a simple Flask/Django API for real-time predictions.\n",
    "- **Monitoring:** Track prediction performance and data drift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b849047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "joblib.dump(best_model, 'inventory_value_model.joblib')\n",
    "print(\"Model saved to inventory_value_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b462c1f",
   "metadata": {},
   "source": [
    "## 11. Conclusion & Next Steps\n",
    " \n",
    "- We built an end-to-end ML pipeline from synthetic data generation to model evaluation.\n",
    "- The Random Forest model achieved an R2 of {r2:.2%}. \n",
    "- Next steps:\n",
    "1. Integrate with real Odoo data.\n",
    "2. Automate data ingestion and retraining pipeline.\n",
    "3. Deploy API and dashboard for stakeholders.\n",
    "4. Continuously monitor and refine the model.\n",
    "\n",
    "\n",
    "> **Ready for production!**  \n",
    "> This solution demonstrates the value of a Data Science Production Engineer in optimizing inventory costs and supporting data-driven decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "production-engineering-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
